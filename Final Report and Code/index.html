<html>
<head>
<title>CS 385 Final Project</title>
<link href='http://fonts.googleapis.com/css?family=Nunito:300|Crimson+Text|Droid+Sans+Mono' rel='stylesheet' type='text/css'>
<link rel="stylesheet" title="Default" href="styles/github.css">
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>  

<link rel="stylesheet" href="highlighting/styles/default.css">
<script src="highlighting/highlight.pack.js"></script>

<style type="text/css">
body {
	margin: 0px;
	width: 100%;
	font-family: 'Crimson Text', serif;
	font-size: 20px;
	background: #fcfcfc;
}
h1 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 28px;
	margin: 25px 0px 0px 0px;
	text-transform: lowercase;

}

h2 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 32px;
	margin: 15px 0px 35px 0px;
	color: #333;	
	word-spacing: 3px;
}

h3 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 26px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}
h4 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 22px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}

h5 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 18px;
	margin: 10px 0px 10px 0px;
	color: #111;
	word-spacing: 2px;
}

p, li {
	color: #444;
}

a {
	color: #DE3737;
}

.container {
	margin: 0px auto 0px auto;
	width: 1160px;
}

#header {
	background: #333;
	width: 100%;
}

#headersub {
	color: #ccc;
	width: 960px;
	margin: 0px auto 0px auto;
	padding: 20px 0px 20px 0px;
}

.chart {
	width: 480px;
}
.lol {
	font-size: 16px;
	color: #888;
	font-style: italic;
}
.sep {
	height: 1px;
	width: 100%;
	background: #999;
	margin: 20px 0px 20px 0px;
}
.footer{
	font-size: 16px;
}
.latex {
	width: 100%;
}

.latex img {
	display: block;
	margin: 0px auto 0px auto;
}

pre {
	font-family: 'Droid Sans Mono';
	font-size: 14px;
}

table td {
  text-align: center;
  vertical-align: middle;
}

table td img {
  text-align: center;
  vertical-align: middle;
}

#contents a {
}
</style>
<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>
</head>
<body>
<div id="header" >
<div id="headersub">
<h1>Sign-Language <span style="color: #DE3737">(John Eggers, Sean Moloney, Luke Rosenberg)</span></h1>
</div>
</div>
<div class="container">

<h2>CS 385 : Real-Time Sign Detection</h2>

<div style="float: right; padding: 20px">
<img src="placeholder.jpg" />
<p style="font-size: 14px">An example of what the detector is passed.</p>
</div>

<h3>Introduction</h3>

<p> 	The goal of our project is to be able to identify traffic signs in real-time. To do this, we decided to employ a combination of several techniques.  We decided that our detector would be built around the idea of a car dash-cam, meaning that signs would most likely always be in motion (seeing as you would be driving by them).  We also decided that, while sign identification would be great, we did not have time to properly implement this feature.  Therefore, we decided to focus purely on identifing a sign's location, and tracking it for the user/driver.</p>

<p>		Our code essentially consists of two parts - an object detection portion, and a motion tracking portion.  The object detection portion's job is to detect the sign in the first place.  It is then the motion tracking portion's job to attempt to calculate/anticipate where the sign will be in the next frame, and therefore providing the most accurate tracking possible.</p>

<div style="clear:both">
<br>
<h3>Approach/Algorithm</h3>

<h4><i>Sign Detection:</i></h4>

<p> 	For the sign detection portion of our code, we originally were going to use the HOG (Histogram of Oriented Gradients) method.  However, due to multiple problems getting VLFeat to work, as well as us finding that this method didn't work so well for how we were reading in video, we switched to using an ACF (Agregate Channel Features) object detector.  ACF is a fast and effective sliding window detector.  It is an evolution of the Viola & Jones (VJ) detector but with an ~1000 fold decrease in false positives (at the same detection rate). ACF is best suited for quasi-rigid object detection (e.g. faces, pedestrians, cars), which we found to be perfect for our sign-detecting needs.</p>

<p>		To perform the ACF object detection, we used MatLab's built-in function 'trainACFObjectDetector.'  We pass in the training data that consists of file-names and bounding-boxes of multiple images in the form of a .mat file.  For this program, we used the LISA (Laboratory for Intelligent and Safe Automobiles) Traffic Sign Data Set to generate our .mat file.  This data-set contains over 47 US sign types, as well as 7,855 annotations on 6,610 frames.  Upon training our detector with this data-set, we then procede to check every frame of the video for signs.</p>

<pre><code>
% code for calling the ACF object detector
for i = 1:length(offset)
    source = imread(sprintf('%s/source_%02d.jpg',data_dir,i));
    mask   = imread(sprintf('%s/mask_%02d.jpg',data_dir,i));
    target = imread(sprintf('%s/target_%02d.jpg',data_dir,i));

</code></pre>

<p>Some sample test images from the LISA data-set:</p>

<table width="500" border=1>
<tr>
<td width="10" height="100">
<img src="placeholder.jpg" width="24%"/>
<img src="placeholder.jpg"  width="24%"/>
<img src="placeholder.jpg" width="24%"/>
<img src="placeholder.jpg" width="24%"/>
</td>
</tr>

<tr>
<td width="10" height="100">
<img src="placeholder.jpg" width="24%"/>
<img src="placeholder.jpg"  width="24%"/>
<img src="placeholder.jpg" width="24%"/>
<img src="placeholder.jpg" width="24%"/>
</td>
</tr>
</table>

<br>
<h4><i>Motion Tracking:</i></h4>

<p> 	For the motion tracking portion of our code, every time a street sign is detected a struct is created for it.  This struct is called a 'track,' and it represents the moving sign object.  This 'track' contains a unique id, the bounding box around the object, its classification score, its age (number of frames since the sign was detected), the total visible count (number of frames where the object was visible), confidence rating, predicted position (where the program predicts where the next bounding box will be), and a Kalman Filter oject.  The Kalman Filter object is one of the most important parts of the tracking/prediction process, as it is an optimal estimation algorithm that combines uncertain information to provide an educated guess on what that object is (or in our case, where an object is going).  It also is fantastic for continuously changing systems, which is why it is so useful for real-time detection.</p>

<p>		In each frame of the video, a function is called to display the tracking results.  This function loops through the array of track and displays them in the form of bounding boxes superimposed on each frame.  There are other functions that are called in the process that update the arrays of tracks based on certain global thresholds, such as age, confidence, visibility, and estimated error tolerance.  To come up with these global parameters, we experimented until we were satisfied with the detector's accuracy.</p>

<pre><code>
% code for using motion detection
for i = 1:length(offset)
    source = imread(sprintf('%s/source_%02d.jpg',data_dir,i));
    mask   = imread(sprintf('%s/mask_%02d.jpg',data_dir,i));
    target = imread(sprintf('%s/target_%02d.jpg',data_dir,i));

</code></pre>

<br>
<h3>Results</h3>

<h4><i>Sign Detection:</i></h4>

<p>When run, our program did a relatively decent job at detecting the signs in the video it was given.  While we were unable to get it to identify each sign individually (due to both time-constraints and multiple crippling errors), we did get it to recognize most types of signs, and detect them with fair accuracy.  There were some issues when signs were distorted (be it due to distortion or bad lighting), but over-all it's detection method seemed to yield relatively robust results.</p>

<h4><i>Motion Tracking:</i></h4>

<p>In terms of motion-tracking, our program did a pretty decent job as well.  While it did have trouble detecting signs that were not moving (since this is supposed to be from a car dash-cam and it expect them to be moving by the window), it was good a tracking signs in motion and approximating where they would be from frame to frame.  While we found we could fix this to some extent by decreasing our global age and confidence thresholds, we determined that this was not worth it due to the large number of false-positives that it consequently produced.</p>

<br>
<center>
<p>
Positive results after running the code:
<p>
<img src="hog_template.png">
<p>
<img src="average_precision.png">
<p>
<img src="hog_template.png">
<p>
<img src="average_precision.png">
<p>
<img src="hog_template.png">
<p>
</center>
<p>

<center>
Negative results after running the code:
<p>
<img src="hog_template.png">
<p>
<img src="average_precision.png">
<p>
</center>

<br>
<h3>Conclusions</h3>
<div style="clear:both" >
<p> 	We encountered quite a few problems throughout this project.  From VLFeat causing us major headaches in the beginning, to having trouble formating the training data from the LISA data-set into a .mat file, it was a challenge from beginning to end.  However, in the process we had the chance to really explore and discover a lot both about MatLab and in object detection in general.  When something broke, we had the opportunity to either fix it, or to try another method.  Often, we would be doing both simultaneously.  What this yielded was a very rich learning experience that gave us practice in areas of detection that we didn't even originally consider (such as our methods for tracking moving objects).  We also got experience working with processing video and working in a real-time enviroment, things we did not originally even consider when starting.</p>

<p>		Given more time, we would really have liked to expand this program to also perform sign identification.  It would have really rounded-out the program and given it more application. However, given the obstacles we had to overcome, we were pleased with the end result and may even come back to this project in the future with the intent of taking it further.</p>

<br>
<p>		Sources: https://pdollar.github.io/toolbox/detector/acfReadme.html; http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6996284; http://cvrr.ucsd.edu/LISA/lisa-traffic-sign-dataset.html; http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/</p>
</div>
</body>
</html>
